<!DOCTYPE html>
<html>

<head>
    <link rel="stylesheet" type="text/css" href="../Css/styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Press+Start+2P&display=swap" rel="stylesheet">
    <title>Arquitectura de computadoras</title>
    <link rel="shortcut icon" href="../Icons/its.png">
</head>

<body>
    <div class="title-bar">
        <img src="../Icons/Mi proyecto.png" alt="Logo">
        Procesamiento paralelo
    </div>

    <ul class="navbar">
        <li><a href="../html/unidad1.html">Unidad 1</a></li>
        <li><a href="../html/unidad2.html">Unidad 2</a></li>
        <li><a href="../html/unidad3.html">Unidad 3</a></li>
        <li><a href="../index.html">Inicio</a></li>
        <li><a href="../html/practicas.html">Pr&aacute;cticas</a></li>
    </ul>

    <div class="index">
        <nav>
            <ul>
                <a href="#4.1">
                    <li>4.1 Aspectos B&aacute;sicos de la Computaci&oacute;n Paralela</li>
                </a>
                <a href="#4.2">
                    <li>4.2 Tipos de Computaci&oacute;n Paralela</li>
                </a>
                <ul>
                    <a href="#4.2.1">
                        <li>4.2.1 Clasificaci&oacute;n</li>
                    </a>
                    <a href="#4.2.2">
                        <li>4.2.2 Arquitectura de Computadoras Secuenciales</li>
                    </a>
                    <a href="#4.2.3">
                        <li>4.2.3 Organizaci&oacute;n de Direcciones de Memoria</li>
                    </a>
                </ul>
                <a href="#4.3">
                    <li>4.3 Sistemas de Memoria Compartida</li>
                </a>
                <ul>
                    <a href="#4.3.1">
                        <li>4.3.1 Redes de Interconexi&oacute;n Din&aacute;micas &oacute; Indirectas</li>
                    </a>
                    <ul>
                        <a href="#4.3.1.1">
                            <li>4.3.1.1 Redes de Medio Compartido</li>
                        </a>
                        <a href="#4.3.1.2">
                            <li>4.3.1.2 Redes Conmutadas</li>
                        </a>
                    </ul>
                </ul>
                <a href="#4.4">
                    <li>4.4 Sistemas de Memoria Distribuida: Multiprocesadores</li>
                </a>
                <ul>
                    <a href="#4.4.1">
                        <li>4.4.1 Redes de Interconexi&oacute;n Est&aacute;ticas</li>
                    </a>
                </ul>
                <a href="#4.5">
                    <li>4.5 Casos de Estudio</li>
                </a>
            </ul>
            </ul>
        </nav>

    </div>

    <div>
        <div class="black-bg">
            <div class="paragraph-with-image">
                <h2 id="4.1">Aspectos b&aacute;sicos de la computaci&oacute;n paralela</h2>
                <p>
                    La computaci&oacute;n paralela es una disciplina que se ocupa de realizar c&aacute;lculos o tareas
                    simult&aacute;neamente
                    utilizando m&uacute;ltiples recursos de procesamiento. En lugar de ejecutar una sola tarea en una
                    computadora secuencial, la computaci&oacute;n paralela divide la carga de trabajo en varias partes
                    m&aacute;s
                    pequeñas y las procesa al mismo tiempo en diferentes unidades de procesamiento, como n&uacute;cleos
                    de CPU
                    o computadoras interconectadas.
                    <br><br>
                    Los aspectos b&aacute;sicos de la computaci&oacute;n paralela incluyen:
                    <br><br>
                    <b>-Granularidad:</b> se refiere al tamaño de las tareas en paralelo. Puede ser gruesa, cuando las
                    tareas
                    son grandes y se dividen en subprocesos independientes, o fina, cuando las tareas se dividen en
                    partes m&aacute;s pequeñas que se ejecutan en paralelo.
                    <br><br>
                    <b>-Comunicaci&oacute;n:</b> es fundamental en la computaci&oacute;n paralela, ya que los diferentes
                    procesos o
                    unidades
                    de procesamiento deben intercambiar informaci&oacute;n. La comunicaci&oacute;n puede ser a
                    trav&eacute;s de la memoria
                    compartida o mediante el paso de mensajes.
                    <br><br>
                    <b>-Sincronizaci&oacute;n:</b> se refiere a la coordinaci&oacute;n de los procesos en paralelo. Es
                    necesario
                    asegurarse de
                    que los procesos se ejecuten en el orden adecuado y que la informaci&oacute;n compartida se
                    sincronice
                    correctamente.
                </p>
            </div>
        </div>
        <div class="white-bg">
            <h2 id="4.2">Tipos de computaci&oacute;n paralela</h2>
            <div class="paragraph-with-image">
                <p>
                    <b>Paralelismo a nivel de bit</b><br>
                    Desde el advenimiento de la integraci&oacute;n a gran escala (VLSI) como tecnolog&iacute;a de
                    fabricaci&oacute;n de chips
                    de computadora en la d&eacute;cada de 1970 hasta alrededor de 1986, la aceleraci&oacute;n en la
                    arquitectura de
                    computadores se lograba en gran medida duplicando el tamaño de la palabra en la computadora, la
                    cantidad de informaci&oacute;n que el procesador puede manejar por ciclo.
                    <br><br>
                    Hist&oacute;ricamente, los microprocesadores de 4 bits fueron sustituidos por unos de 8 bits, luego
                    de 16
                    bits y 32 bits, esta tendencia general lleg&oacute; a su fin con la introducci&oacute;n de
                    procesadores de 64
                    bits, lo que ha sido un est&aacute;ndar en la computaci&oacute;n de prop&oacute;sito general durante
                    la &uacute;ltima d&eacute;cada.
                    <br><br>
                    <b>Paralelismo a nivel de instrucci&oacute;n</b>
                    Los procesadores modernos tienen ''pipeline'' de instrucciones de varias etapas. Cada etapa en el
                    pipeline corresponde a una acci&oacute;n diferente que el procesador realiza en la
                    instrucci&oacute;n
                    correspondiente a la etapa; un procesador con un pipeline de N etapas puede tener hasta n
                    instrucciones diferentes en diferentes etapas de finalizaci&oacute;n.
                    <br><br>
                    <b>Paralelismo de datos</b>
                    El paralelismo de datos es el paralelismo inherente en programas con ciclos, que se centra en la
                    distribuci&oacute;n de los datos entre los diferentes nodos computacionales que deben tratarse en
                    paralelo.
                    Muchas de las aplicaciones cient&iacute;ficas y de ingenier&iacute;a muestran paralelismo de datos.
                    <br><br>
                    <img src="../Images/Unidad4/paralelismo.png">
                    <br><br>
                    Una dependencia de terminaci&oacute;n de ciclo es la dependencia de una iteraci&oacute;n de un ciclo
                    en la salida
                    de una o m&aacute;s iteraciones anteriores. Las dependencias de terminaci&oacute;n de ciclo evitan
                    la
                    paralelizaci&oacute;n de ciclos.
                    <br><br>
                    <b>Paralelismo de tareas</b><br>
                    Es un paradigma de la programaci&oacute;n concurrente que consiste en asignar distintas tareas a
                    cada uno
                    de los procesadores de un sistema de c&oacute;mputo. En consecuencia, cada procesador
                    efectuar&aacute; su propia
                    secuencia de operaciones. En su modo m&aacute;s general, el paralelismo de tareas se representa
                    mediante un
                    grafo de tareas, el cual es subdividido en subgrafos que son luego asignados a diferentes
                    procesadores.
                </p>
            </div>
        </div>
        <div class="black-bg">
            <h2 id="4.2.1">Clasificaci&oacute;n</h2>
            <div class="paragraph-with-image">
                <p>
                    Las computadoras paralelas se pueden clasificar de acuerdo con el nivel en el que el hardware
                    soporta paralelismo. Esta clasificaci&oacute;n es an&aacute;loga a la distancia entre los nodos
                    b&aacute;sicos de
                    c&oacute;mputo. Estos no son excluyentes entre s&iacute;, por ejemplo, los grupos de
                    multiprocesadores sim&eacute;tricos
                    son relativamente comunes.
                    <br><br>
                    <b>COMPUTACI&oacute;N MULTIN&uacute;CLEO</b><br>
                    Un procesador multin&uacute;cleo es un procesador que incluye m&uacute;ltiples unidades de
                    ejecuci&oacute;n (n&uacute;cleos) en
                    el mismo chip. Un procesador multin&uacute;cleo puede ejecutar m&uacute;ltiples instrucciones por
                    ciclo de
                    secuencias de instrucciones m&uacute;ltiples.
                    <br><br>
                    <b>MULTIPROCESAMIENTO SIM&eacute;TRICO</b><br>
                    Un multiprocesador sim&eacute;trico (SMP) es un sistema computacional con m&uacute;ltiples
                    procesadores id&eacute;nticos
                    que comparten memoria y se conectan a trav&eacute;s de un bus. La contenci&oacute;n del bus previene
                    el escalado
                    de esta arquitectura.
                    <br><br>
                    <b>COMPUTACI&oacute;N EN CL&uacute;STER</b><br>
                    Un cl&uacute;ster es un grupo de ordenadores d&eacute;bilmente acoplados que trabajan en estrecha
                    colaboraci&oacute;n, de
                    modo que en algunos aspectos pueden considerarse como un solo equipo.
                    <br><br>
                    <b>PROCESAMIENTO PARALELO MASIVO</b><br>
                    Tienden a ser m&aacute;s grandes que los cl&uacute;steres, con «mucho m&aacute;s» de 100
                    procesadores. En un MPP, cada
                    CPU tiene su propia memoria y una copia del sistema operativo y la aplicaci&oacute;n.
                    <br><br>
                    <b>COMPUTACI&oacute;N DISTRIBUIDA</b><br>
                    La computaci&oacute;n distribuida es la forma m&aacute;s distribuida de la computaci&oacute;n
                    paralela. Se hace uso de
                    ordenadores que se comunican a trav&eacute;s de la Internet para trabajar en un problema dado.
                    <br><br>
                    <b>COMPUTADORAS PARALELAS ESPECIALIZADAS</b><br>
                    Dentro de la computaci&oacute;n paralela, existen dispositivos paralelos especializados que generan
                    inter&eacute;s. Aunque no son espec&iacute;ficos para un dominio, tienden a ser aplicables
                    s&oacute;lo a unas pocas
                    clases de problemas paralelos.
                    <br><br>
                    <b>C&oacute;MPUTO RECONFIGURABLE CON ARREGLOS DE COMPUERTAS PROGRAMABLES</b><br>
                    El c&oacute;mputo reconfigurable es el uso de un arreglo de compuertas programables (FPGA) como
                    coprocesador de un ordenador de prop&oacute;sito general.
                    <br><br>
                    <b>C&oacute;MPUTO DE PROP&oacute;SITO GENERAL EN UNIDADES DE PROCESAMIENTO GR&aacute;FICO
                        (GPGPU)</b><br>
                    Es una tendencia relativamente reciente en la investigaci&oacute;n de ingenier&iacute;a
                    inform&aacute;tica. Los GPUs son
                    co-procesadores que han sido fuertemente optimizados para procesamiento de gr&aacute;ficos por
                    computadora.
                    <br><br>
                    <b>CIRCUITOS INTEGRADOS DE APLICACI&oacute;N ESPEC&iacute;FICA</b><br>
                    Debido a que un ASIC (por definici&oacute;n) es espec&iacute;fico para una aplicaci&oacute;n dada,
                    puede ser
                    completamente optimizado para esa aplicaci&oacute;n. Como resultado, para una aplicaci&oacute;n
                    dada, un ASIC
                    tiende a superar a un ordenador de prop&oacute;sito general.
                    <br><br>
                    <b>PROCESADORES VECTORIALES</b><br>
                    Pueden ejecutar la misma instrucci&oacute;n en grandes conjuntos de datos. Tienen operaciones de
                    alto nivel
                    que trabajan sobre arreglos lineales de n&uacute;meros o vectores.
                </p>
            </div>
        </div>
        <div class="white-bg">
            <div class="paragraph-with-image">
                <h2 id="4.2.2">Arquitectura de Computadoras Secuenciales</h2>
                <p>
                    La arquitectura de computadoras secuenciales es el modelo tradicional de procesamiento secuencial en
                    el que las instrucciones se ejecutan una tras otra en un único hilo de ejecución. La CPU sigue un
                    flujo de control secuencial y ejecuta las instrucciones en orden.
                    <br><br>
                    Este tipo de arquitectura se basa en el modelo de Von Neumann, que consta de una unidad de control,
                    una unidad aritmético-lógica, una memoria principal y dispositivos de entrada/salida. Los programas
                    secuenciales se dividen en instrucciones que se cargan desde la memoria y se ejecutan una tras otra.
                </p>
            </div>
        </div>
        <div class="black-bg">
            <div class="paragraph-with-image">
                <h2 id="4.2.3">Organizaci&oacute;n de direcciones de memoria</h2>
                <p>
                    En los sistemas de computación paralela, la organización de las direcciones de memoria es un aspecto
                    importante a considerar. Permite acceder a los datos y las instrucciones almacenadas en la memoria.
                    <br><br>
                    Hay diferentes esquemas de organización de direcciones de memoria, como la memoria distribuida, en
                    la que cada unidad de procesamiento tiene su propia memoria local, y la memoria compartida, en la
                    que varias unidades de procesamiento comparten la misma memoria.
                </p>
                <img src="../Images/Unidad1/ram.jpg">
            </div>
        </div>
        <div class="white-bg">
            <div class="paragraph-with-image">
                <h2 id="4.3">Sistemas de memoria compartida</h2>
                <p>
                    Los sistemas de memoria compartida son aquellos en los que múltiples unidades de procesamiento
                    comparten un espacio de direcciones de memoria común. Esto permite a los procesos comunicarse y
                    compartir datos a través de la memoria compartida, lo que simplifica la programación paralela.
                    <br><br>
                    <img src="../Images/Unidad4/memoriacompartida.png">
                    <br><br>
                    <b>ESTRUCTURA DE LOS MULTIPROCESADORES DE MEMORIA COMPARTIDA</b><br>
                    La mayoría de los multiprocesadores comerciales son del tipo UMA (Uniform Memory Access): todos los
                    procesadores tienen igual tiempo de acceso a la memoria compartida. En la arquitectura UMA los
                    procesadores se conectan a la memoria a través de un bus, una red multietapa o un conmutador de
                    barras cruzadas (red multietapa o un conmutador de barras cruzadas (crossbar crossbar) y disponen de
                    su propia ) y disponen de su propia memoria caché. Los procesadores tipo NUMA (Non Uniform Memory
                    Access) presentan tiempos de acceso a la memoria compartida que dependen de la ubicación del
                    elemento de proceso y la memoria.
                </p>
            </div>
        </div>
        <div class="black-bg">
            <div class="paragraph-with-image">
                <h2 id="4.3.1">Redes de interconexi&oacute;n din&aacute;micas &oacute; indirectas</h2>
                <p>
                    En el contexto de la arquitectura de computadoras, las redes de interconexión dinámicas o indirectas
                    se refieren a los esquemas utilizados para conectar y comunicar los componentes de un sistema
                    computacional, como procesadores, memoria y dispositivos de entrada/salida. Estas redes proporcionan
                    una forma flexible y eficiente de transferir datos entre los distintos elementos del sistema.
                    <br><br>
                    Un ejemplo común de una red de interconexión dinámica en arquitectura de computadoras es el sistema
                    de interconexión utilizado en los supercomputadores. Estos sistemas están diseñados para realizar
                    tareas computacionalmente intensivas y requieren una alta capacidad de procesamiento y comunicación
                    entre los nodos.
                    <br><br>
                    En lugar de utilizar una arquitectura de bus tradicional, donde todos los componentes están
                    conectados directamente a un único bus compartido, los supercomputadores suelen emplear
                    arquitecturas de red más complejas. Estas arquitecturas utilizan enlaces de comunicación de alta
                    velocidad, como redes toroidales, redes en malla o redes hipercúbicas, para interconectar los nodos
                    de procesamiento y almacenamiento.
                    <br><br>
                    En una red de interconexión dinámica, los nodos pueden comunicarse indirectamente mediante saltos a
                    través de otros nodos intermedios. Esto permite una comunicación eficiente y escalable en sistemas
                    con un gran número de componentes. Además, estas redes suelen ser adaptables, lo que significa que
                    pueden reconfigurarse dinámicamente para adaptarse a cambios en la carga de trabajo o a fallos en
                    los nodos.
                </p>
            </div>
        </div>
        <div class="white-bg">
            <h2 id="4.3.1.1">Redes de medio Compartido</h2>
            <div class="paragraph-with-image">
                <p>
                    Es un tipo de arquitectura de red en la que múltiples dispositivos comparten un medio de
                    comunicación
                    común para enviar y recibir datos. En esta arquitectura, los dispositivos se conectan físicamente al
                    mismo medio de transmisión, como un cable o una línea de transmisión, y deben coordinarse para
                    acceder al medio y transmitir sus datos.
                    <br><br>
                    Un ejemplo común de una red de medio compartido en arquitectura de computadoras es Ethernet, que
                    utiliza un cable compartido o un segmento de red para conectar múltiples dispositivos, como
                    computadoras, servidores o impresoras. En Ethernet, los dispositivos utilizan un protocolo llamado
                    CSMA/CD (Acceso Múltiple por Detección de Portadora con Detección de Colisiones) para gestionar el
                    acceso al medio compartido.
                    <br><br>
                    En una red de medio compartido, los dispositivos deben seguir ciertas reglas para evitar colisiones
                    de datos cuando intentan transmitir al mismo tiempo. El protocolo CSMA/CD utilizado en Ethernet
                    permite que los dispositivos "escuchen" el medio antes de transmitir. Si un dispositivo detecta que
                    el medio está ocupado por otra transmisión, espera un período de tiempo aleatorio antes de volver a
                    intentar transmitir. Si dos dispositivos intentan transmitir al mismo tiempo y se produce una
                    colisión, ambos dispositivos interrumpen la transmisión y esperan un tiempo aleatorio antes de
                    volver a intentarlo.
                    <br><br>
                    Aunque las redes de medio compartido como Ethernet son ampliamente utilizadas y ofrecen una solución
                    económica para conectar múltiples dispositivos, también presentan algunas limitaciones. El
                    rendimiento de la red puede verse afectado a medida que aumenta el número de dispositivos conectados
                    y las colisiones se vuelven más probables. Además, debido a que todos los dispositivos comparten el
                    mismo medio, el ancho de banda disponible se divide entre los dispositivos, lo que puede limitar la
                    velocidad de transmisión.
                </p>
                <img src="../Images/Unidad4/redesdemediocompartido.png">
            </div>
        </div>
        <div class="black-bg">
            <center>
                <h2 id="4.3.1.2">Redes conmutadas</h2>
            </center>
            <div class="paragraph-with-image">
                <p>
                    <b>CONEXIÓN POR CONMUTADORES CROSSBAR</b><br>
                    Cada procesador (Pi) y cada módulo de memoria (Mi) tienen su propio bus. Existe un conmutador (S) en
                    los puntos de intersección que permite conectar un bus de memoria con un bus de procesador. Para
                    evitar conflictos cuando más de un procesador pretende acceder al mismo módulo de memoria se
                    establece un orden de prioridad. Se trata de una red sin bloqueo con una conectividad completa pero
                    de alta complejidad.
                    <br><br>
                    <img src="../Images/Unidad4/crossbar.png">
                    <br><br>
                    <b>CONEXIÓN POR RED MULTIETAPA</b><br>
                    - Representan una alternativa intermedia de conexión entre el bus y el crossbar.<br>
                    - Es de menor complejidad que el crossbar pero mayor que el bus simple.<br>
                    - La conectividad es mayor que la del bus simple pero menor que la del crossbar.<br>
                    - Se compone de varias etapas alternativas de conmutadores simples y redes de interconexión.<br>
                    <br>
                    <img src="../Images/Unidad4/multietapa.png">
                </p>
            </div>
        </div>
        <div class="white-bg">
            <center>
                <h2 id="4.4">Sistemas de memoria Distribuida: Multiprocesadores</h2>
            </center>
            <div class="paragraph-with-image">
                <p>
                    Los sistemas de memoria distribuida o multicomputadores pueden ser de dos tipos básicos. El primer
                    de ellos consta de un único computador con múltiples CPUs comunicadas por un bus de datos mientras
                    que en el segundo se utilizan múltiples computadores, cada uno con su propio procesador, enlazados
                    por una red de interconexión más o menos rápida.
                    <br><br>
                    Sobre los sistemas de multicomputadores de memoria distribuida, se simula memorias compartidas. Se
                    usan los mecanismos de comunicación y sincronización de sistemas multiprocesadores.
                    <br><br>
                    Un clúster es un tipo de arquitectura paralela distribuida que consiste de un conjunto de
                    computadores independientes interconectados operando de forma conjunta como único recurso
                    computacional sin embargo, cada computador puede utilizarse de forma independiente o separada.
                    <br><br>
                    En esta arquitectura, el computador paralelo es esencialmente una colección de procesadores
                    secuenciales, cada uno con su propia memoria local, que pueden trabajar conjuntamente.
                    <br><br>
                    Cada nodo tiene rápido acceso a su propia memoria y acceso a la memoria de otros nodos mediante una
                    red de comunicaciones, habitualmente una red de comunicaciones de alta velocidad.
                    <br><br>
                    Los datos son intercambiados entre los nodos como mensajes a través de la red.
                    <br><br>
                    Una red de ordenadores, especialmente si disponen de una interconexión de alta velocidad, puede ser
                    vista como un multicomputador de memoria distribuida y como tal ser utilizada para resolver
                    problemas mediante computación paralela.
                </p>
            </div>
        </div>
        <div class="black-bg">
            <h2 id="4.4.1">Redes de interconexi&oacute;n est&aacute;ticas</h2>
            <div class="paragraph-with-image">
                <p>
                    Los multicomputadores utilizan redes estáticas con enlaces directos entre nodos. Cuando un nodo
                    recibe un mensaje lo procesa si viene dirigido a dicho nodo. Si el mensaje no va dirigido al nodo
                    receptor lo reenvía a otro por alguno de sus enlaces de salida siguiendo un protocolo de
                    encaminamiento.
                    <br><br>
                    <img src="../Images/Unidad4/reddeinterconexionestatica.png">
                    <br><br>
                    <b>Propiedades más significativas</b><br>
                    -Topología de la red: determina el patrón de interconexión entre nodos.<br>
                    -Diámetro de la red: distancia máxima de los caminos más cortos entre dos nodos de la red.<br>
                    -Latencia: retardo de tiempo en el peor caso para un mensaje transferido a través de la red.<br>
                    -Ancho de banda: Transferencia máxima de datos en Mbytes/segundo.<br>
                    -Escalabilidad: posibilidad de expansión modular de la red.<br>
                    -Grado de un nodo: número de enlaces o canales que inciden en el nodo.<br>
                    -Algoritmo de encaminamiento: determina el camino que debe seguir un mensaje desde el nodo emisor al
                    nodo receptor.
                </p>
            </div>
        </div>
        <div class="white-bg">
            <div class="paragraph-with-image">
                <h2 id="4.5">Casos de estudio</h2>
                <p>
                    <b>Simulación de sistemas físicos complejos: </b>La computación paralela se utiliza ampliamente en la
                    simulación de sistemas físicos complejos, como el clima y la física de partículas. En el campo de la
                    climatología, los modelos numéricos requieren un alto grado de paralelismo para simular el
                    comportamiento atmosférico a gran escala. Los supercomputadores paralelos se utilizan para ejecutar
                    modelos climáticos y proporcionar pronósticos meteorológicos precisos.
                    En la física de partículas, experimentos como el Gran Colisionador de Hadrones (LHC) generan grandes
                    cantidades de datos. La computación paralela se utiliza para procesar y analizar estos datos,
                    buscando patrones y partículas subatómicas. Los sistemas de memoria distribuida son especialmente
                    útiles en este caso, ya que permiten el procesamiento en paralelo de grandes volúmenes de datos.
                    <br><br>
                    <b>Minería de datos y aprendizaje automático: </b>Con el crecimiento masivo de los conjuntos de datos en
                    diversos campos, la computación paralela se ha convertido en una herramienta esencial para la
                    minería de datos y el aprendizaje automático. Algoritmos como el aprendizaje profundo requieren una
                    gran cantidad de cálculos intensivos que se pueden acelerar enormemente mediante la computación
                    paralela.
                    Los sistemas de memoria compartida y distribuida se utilizan para entrenar modelos de aprendizaje
                    automático en paralelo, dividiendo los datos y las tareas de procesamiento entre múltiples
                    procesadores. Esto permite realizar el entrenamiento más rápido y manejar grandes conjuntos de datos
                    de manera eficiente.
                    <br><br>
                    <b>Renderización de gráficos en tiempo real:</b> En la industria de los videojuegos y la simulación, la
                    renderización de gráficos en tiempo real es esencial para lograr una experiencia visual fluida y
                    realista. La computación paralela se utiliza en el procesamiento gráfico para acelerar los cálculos
                    complejos necesarios para generar imágenes y efectos visuales en tiempo real.
                    Las tarjetas gráficas (GPU) se utilizan comúnmente en la renderización paralela, ya que están
                    diseñadas específicamente para ejecutar múltiples tareas en paralelo. Los desarrolladores de juegos
                    y software de renderización aprovechan la capacidad de las GPUs para dividir las tareas de
                    renderización entre múltiples hilos y procesadores, lo que permite una renderización rápida y
                    eficiente de escenas complejas en tiempo real.
                    <br><br>
                    Estos son solo algunos ejemplos de casos de estudio en los que la computación paralela ha demostrado
                    ser invaluable. En general, la computación paralela se utiliza en cualquier campo que requiera un
                    procesamiento intensivo y rápido de datos, como la investigación científica, la simulación de
                    sistemas complejos, el análisis de grandes conjuntos de datos y la generación de gráficos en tiempo
                    real.
                </p>
            </div>
        </div>
    </div>
</body>

</html>